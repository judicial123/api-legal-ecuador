import os
from openai import OpenAI
from flask import Flask, request, jsonify
from llama_index import VectorStoreIndex
from llama_index.vector_stores import PineconeVectorStore
from pinecone import Pinecone
from llama_index.embeddings.openai import OpenAIEmbedding
from llama_index import ServiceContext
import traceback
import re
import unicodedata

import requests
from bs4 import BeautifulSoup
from llama_index import Document  # Ya est√°s importando VectorStoreIndex, te falta Document

# ============= CONFIGURACI√ìN =============
CONFIG = {
    "OPENAI_API_KEY": os.getenv("OPENAI_API_KEY"),
    "PINECONE_API_KEY": os.getenv("PINECONE_API_KEY"),
    "INDEX_NAME": os.getenv("INDEX_NAME"),
    "PINECONE_ENV": os.getenv("PINECONE_ENV"),
    "OPENAI_MODEL": "gpt-3.5-turbo",
    "TEMPERATURE": 0.3,
    "MAX_TOKENS": 2000,
    "GOOGLE_SEARCH_API_KEY": os.getenv("GOOGLE_SEARCH_API_KEY"),
    "GOOGLE_CX": os.getenv("GOOGLE_CX")
}


MATH_KEYWORDS = ['calcular', 'c√°lculo', 'f√≥rmula', 'sumar', 'restar', 'multiplicar', 'dividir']
TOP_K_RESULTS = 25
SIMILARITY_THRESHOLD = 0.5
MAX_ARTICULOS_CON_TEXTO = 5

app = Flask(__name__)

# ============= UTILIDADES =============

def normalizar(texto):
    return ''.join(
        c for c in unicodedata.normalize('NFD', texto)
        if unicodedata.category(c) != 'Mn'
    ).lower()

# ============= LLAMA INDEX =============

pc = Pinecone(api_key=CONFIG["PINECONE_API_KEY"], environment=CONFIG["PINECONE_ENV"])
pinecone_index = pc.Index(CONFIG["INDEX_NAME"])

vector_store = PineconeVectorStore(
    pinecone_index=pinecone_index
)

embed_model = OpenAIEmbedding(
    model="text-embedding-3-large",
    api_key=CONFIG["OPENAI_API_KEY"]
)

# Cargar el √≠ndice de Pinecone donde est√°n los contratos
contratos_index = VectorStoreIndex.from_vector_store(
    PineconeVectorStore(
        pinecone_index=pc.Index("indice-contratos-legales"),
        text_key="text"
    ),
    service_context=ServiceContext.from_defaults(embed_model=embed_model)
)

service_context = ServiceContext.from_defaults(embed_model=embed_model)

index = VectorStoreIndex.from_vector_store(
    vector_store=vector_store,
    service_context=service_context
)

openai_client = OpenAI(api_key=CONFIG["OPENAI_API_KEY"])

# ============= RESPUESTA LEGAL =============

def generate_legal_response(question, context_docs, contexto_practico=None):
    system_prompt = """
Eres un abogado especialista en derecho ecuatoriano. Tu tarea es responder EXCLUSIVAMENTE con base en los textos legales entregados a continuaci√≥n. Est√° TERMINANTEMENTE PROHIBIDO utilizar conocimiento externo, suposiciones, interpretaciones o completar informaci√≥n m√°s all√° de lo provisto.

üß† Objetivo general:
Redacta una respuesta √∫til, clara y jur√≠dica que pueda ser comprendida tanto por ciudadanos sin formaci√≥n legal como por abogados.

ü´± Empat√≠a inicial:
Si la pregunta revela angustia, preocupaci√≥n o un problema delicado (como c√°rcel, salud, familia, etc.), comienza con una frase emp√°tica y humana, como: ‚ÄúEntendemos lo dif√≠cil que puede ser esta situaci√≥n‚Ä¶‚Äù o ‚ÄúLamentamos lo ocurrido y con gusto le orientamos‚Ä¶‚Äù.

üìò Estructura obligatoria:
1. Da una respuesta clara y directa a la pregunta, explicando el contenido legal con palabras sencillas.
2. Cada afirmaci√≥n debe mencionar de qu√© art√≠culo y qu√© c√≥digo o ley proviene, si aplica.
3. Incluye citas textuales relevantes del texto legal, incluso si est√°n truncadas.
4. Finaliza siempre con la frase: ‚ÄúMe baso en [art√≠culos citados]‚Äù.

‚ö†Ô∏è Reglas estrictas:
- NO cites art√≠culos, c√≥digos o leyes que no est√©n literalmente presentes en el contexto legal proporcionado.
- NO utilices jurisprudencia, doctrina, interpretaci√≥n propia ni conocimiento externo.
- NO completes ideas que no est√©n expresamente contenidas en el texto legal.
- Si no hay normativa aplicable, responde exactamente: ‚ÄúNo encontr√© normativa aplicable. No me baso en ning√∫n art√≠culo.‚Äù
"""

    context_text = "\nDOCUMENTOS LEGALES:\n" + "\n".join(
        f"{doc['codigo']} Art.{doc['articulo']}: {doc['texto'][:600]}"
        for doc in context_docs
    )

    if contexto_practico:
        context_text += f"\n\nüßæ Contexto pr√°ctico adicional: {contexto_practico}"

    response = openai_client.chat.completions.create(
        model=CONFIG["OPENAI_MODEL"],
        messages=[
            {"role": "system", "content": system_prompt.strip()},
            {"role": "user", "content": f"{question}\n\n{context_text}"}
        ],
        temperature=CONFIG["TEMPERATURE"],
        max_tokens=CONFIG["MAX_TOKENS"]
    )

    respuesta = response.choices[0].message.content.strip()
    tokens_usados = response.usage.total_tokens if response.usage else 0
    return respuesta, tokens_usados



# ============= RESPUESTA LEGAL 5 =============
def generate_legal_response5(question, context_docs, contexto_practico=None):
    """
    Firma y retorno id√©nticos al original:
    - Params: (question, context_docs, contexto_practico=None)
    - Return: (respuesta:str, tokens_usados:int)

    Cambios clave:
    - Compatibilidad GPT-5: usa max_completion_tokens y NO env√≠a temperature.
    - Backward compatible (GPT-3.5/4): usa max_tokens y temperature.
    - Sin documentos: fallback con prefijo obligatorio y orientaci√≥n general.
    """
    model = CONFIG.get("OPENAI_MODEL", "gpt-5-mini")
    is_gpt5 = str(model).startswith("gpt-5")
    max_out = int(CONFIG.get("MAX_TOKENS", 2000))  # seguimos respetando tu config

    # =============== 1) Sin documentos ‚Üí Fallback con prefijo obligatorio ===============
    if not context_docs:
        fallback_prefix = "no encontr√© normativa oficial, sin embargo "
        system_prompt_fb = (
            "Eres un abogado ecuatoriano. No tienes documentos normativos para citar. "
            "Puedes usar conocimiento general para orientar, pero NO cites art√≠culos, c√≥digos ni n√∫meros de ley; "
            "evita montos y plazos exactos y aclara que es orientaci√≥n general. "
            f"Tu respuesta DEBE comenzar EXACTAMENTE con: \"{fallback_prefix}\" (respetando min√∫sculas) "
            "y luego ofrecer orientaci√≥n breve y √∫til. Sugiere confirmar en fuentes oficiales (Funci√≥n Judicial, SRI, IESS, MDT) "
            "y consultar con un abogado cuando aplique."
        )
        user_msg_fb = (
            "Formato:\n"
            f"- Comienza exacto con: \"{fallback_prefix}\".\n"
            "- Ofrece 5‚Äì8 frases o bullets pr√°cticos, claros y accionables.\n"
            "- Indica que es orientaci√≥n general sin base normativa.\n\n"
            f"Pregunta del usuario:\n{question}"
        )

        kwargs = dict(model=model, messages=[
            {"role": "system", "content": system_prompt_fb},
            {"role": "user", "content": user_msg_fb}
        ])
        if is_gpt5:
            kwargs["max_completion_tokens"] = max_out
        else:
            kwargs["temperature"] = CONFIG.get("TEMPERATURE", 0.3)
            kwargs["max_tokens"] = max_out

        resp = openai_client.chat.completions.create(**kwargs)
        respuesta = (resp.choices[0].message.content or "").strip()
        tokens_usados = resp.usage.total_tokens if getattr(resp, "usage", None) else 0
        return respuesta, tokens_usados

    # =============== 2) Con documentos ‚Üí Modo estricto (solo lo del contexto) ===============
    system_prompt = """
Eres un abogado ecuatoriano. RESPONDE SOLO con base en los ‚ÄúDOCUMENTOS LEGALES‚Äù provistos.
Prohibido conocimiento externo, suposiciones o jurisprudencia que no est√© en esos documentos.

Estilo:
- Claro y directo, lenguaje llano.
- Solo una frase emp√°tica si hay angustia evidente.
- Prioriza los documentos en el orden entregado.

Estructura obligatoria:
1) Respuesta directa (2‚Äì4 frases) que resuelva la duda con palabras sencillas.
2) Fundamento con citas: menciona [C√ìDIGO Art. N] por cada afirmaci√≥n.
3) Citas textuales breves (10‚Äì30 palabras) de los art√≠culos, entre comillas.
4) Cierre EXACTO: ‚ÄúMe baso en [art√≠culos citados]‚Äù.

Reglas de rigor:
- No infieras nada que no est√© textual en los documentos.
- Si una afirmaci√≥n no puede trazarse a un art√≠culo citado, elim√≠nala.
- Cuando un art√≠culo se cita varias veces, escribe su referencia una sola vez en el cierre.
""".strip()

    context_text = "\nDOCUMENTOS LEGALES:\n" + "\n".join(
        f"{doc['codigo']} Art.{doc['articulo']}: {doc['texto'][:600]}"
        for doc in context_docs
    )

    if contexto_practico:
        context_text += f"\n\nüßæ Contexto pr√°ctico adicional: {contexto_practico}"

    kwargs = dict(model=model, messages=[
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": f"{question}\n\n{context_text}"}
    ])
    if is_gpt5:
        kwargs["max_completion_tokens"] = max_out
    else:
        kwargs["temperature"] = CONFIG.get("TEMPERATURE", 0.3)
        kwargs["max_tokens"] = max_out

    response = openai_client.chat.completions.create(**kwargs)
    respuesta = (response.choices[0].message.content or "").strip()
    tokens_usados = response.usage.total_tokens if getattr(response, "usage", None) else 0
    return respuesta, tokens_usados

# ===============  enpresario ===============

def generate_legal_response_empresario(question, context_docs, contexto_practico=None):
    """
    MISMA FIRMA Y RETORNO:
    - Params: (question, context_docs, contexto_practico=None)
    - Return: (respuesta:str, tokens_usados:int)

    Implementa flujo din√°mico:
    1) Section Planner (IA) decide 3‚Äì10 secciones √∫tiles para gerencia (siempre incluye primero ‚Äúüß≠ Respuesta ejecutiva‚Äù
       y al final ‚Äúüìö Fuentes consultadas‚Äù).
    2) Web CSE (gob.ec) para soporte operativo. Si no hay fuentes, el Writer puede usar conocimiento del modelo.
    3) Answer Writer usa: LEGAL_FACTS (tus art√≠culos) -> WEB -> Conocimiento del LLM (fallback).
       Inserta citas inline [C√ìDIGO Art. N] cuando aplique.
    4) Quality Gate: verifica secciones planeadas, ‚Äúanswer-first‚Äù, tablas si se prometen, y fuentes (si existen).
    5) Agrega ‚öñÔ∏è Fundamento legal al final (solo con tus context_docs, con citas textuales cortas).
    6) (Opcional) Anexa ‚Äúüß© Notas operativas (no normativo)‚Äù si se recibe `contexto_practico`.

    NUEVO:
    - Inserta al final de cada secci√≥n (excepto ‚Äúüìö Fuentes consultadas‚Äù) un enlace corto ‚Äúüîó <ALIAS>‚Äù
      a la mejor fuente .gob.ec utilizada para esa secci√≥n.
    - Reemplaza el contenido de ‚Äúüìö Fuentes consultadas‚Äù por una lista HTML <ul> con 3‚Äì7 enlaces deduplicados por dominio.
    """
    import os, json, re, html
    from urllib.parse import urlparse
    import requests

    # -------- Config del modelo --------
    model = CONFIG.get("OPENAI_MODEL", "gpt-5-mini")
    is_gpt5 = str(model).startswith("gpt-5")
    max_out = int(CONFIG.get("MAX_TOKENS", 2000))
    temperature = float(CONFIG.get("TEMPERATURE", 0.3))

    # -------- Config Google CSE --------
    GOOGLE_API_KEY = CONFIG.get("GOOGLE_SEARCH_API_KEY") or os.getenv("GOOGLE_SEARCH_API_KEY")
    GOOGLE_CX = CONFIG.get("GOOGLE_CX") or os.getenv("GOOGLE_CX")

    # ===================== Helpers =====================

    def _google_cse(q, n=5):
        """Busca en gob.ec. Devuelve lista [{title,link,snippet}]."""
        items = []
        if not (GOOGLE_API_KEY and GOOGLE_CX):
            return items
        try:
            resp = requests.get(
                "https://www.googleapis.com/customsearch/v1",
                params={
                    "key": GOOGLE_API_KEY,
                    "cx": GOOGLE_CX,
                    "q": q,
                    "siteSearch": "gob.ec",
                    "siteSearchFilter": "i",
                    "num": min(max(n, 1), 10),
                },
                timeout=12,
            )
            data = resp.json()
            for it in (data.get("items") or [])[:n]:
                items.append({
                    "title": (it.get("title") or "").strip(),
                    "link": (it.get("link") or "").strip(),
                    "snippet": (it.get("snippet") or "").strip()
                })
        except Exception:
            pass
        return items

    def _mk_snippets(results, cap=8):
        """Lista √∫nica por URL (m√°x cap)."""
        out, seen = [], set()
        for r in results:
            u = r.get("link") or ""
            if u and u not in seen:
                out.append(r)
                seen.add(u)
            if len(out) >= cap:
                break
        return out

    def _mk_web_text(snips):
        """Bloque compacto de fuentes para el prompt del Writer."""
        if not snips:
            return "No se hallaron fuentes oficiales en gob.ec para esta consulta."
        lines = []
        for r in snips:
            t = r.get("title", "Fuente")
            u = r.get("link", "")
            s = r.get("snippet", "")
            lines.append("T√≠tulo: " + t + "\nURL: " + u + "\nExtracto: " + s)
        return "\n\n".join(lines)

    def _short_quote(txt, min_w=10, max_w=25):
        """Cita corta 10‚Äì25 palabras."""
        if not txt:
            return ""
        clean = " ".join(txt.split())
        words = clean.split(" ")
        if len(words) <= max_w:
            return clean
        end = max(min_w, min(max_w, 20))
        return " ".join(words[:end])

    def _mk_fundamento(docs):
        """Bloque final ‚öñÔ∏è Fundamento legal solo con tus context_docs."""
        articulos, usados = [], []
        for d in docs or []:
            codigo = (d.get("codigo") or "").strip()
            art = (d.get("articulo") or "").strip()
            texto = (d.get("texto") or "").strip()
            if not (codigo and art and texto):
                continue
            ref = f"{codigo} Art. {art}"
            cita = _short_quote(texto, 10, 25)
            articulos.append(f"- [{ref}] ‚Äú{html.escape(cita)}‚Äù.")
            usados.append(ref)
            if len(articulos) >= 6:
                break
        if not articulos:
            return ""
        cierre = "Me baso en [" + ", ".join(usados) + "]."
        return "‚öñÔ∏è Fundamento legal\n" + "\n".join(articulos) + "\n\n" + cierre

    def _allowed_refs_from_docs(docs):
        """Lista de referencias v√°lidas 'C√ìDIGO Art. N' para validar citas inline (si lo usas)."""
        refs = []
        for d in docs or []:
            codigo = (d.get("codigo") or "").strip()
            art = (d.get("articulo") or "").strip()
            if codigo and art:
                refs.append(f"{codigo} Art. {art}")
        return set(refs)

    def _compact_legal_text(docs, cap=12):
        """Bloque compacto de art√≠culos para el Writer (no URLs)."""
        lines = []
        for d in (docs or [])[:cap]:
            cod = (d.get("codigo") or "").strip()
            art = (d.get("articulo") or "").strip()
            txt = (d.get("texto") or "").strip()
            if cod and art and txt:
                lines.append(f"{cod} Art.{art}: {txt[:600]}")
        return "\n".join(lines) if lines else "(sin documentos)"

    def _answer_first_ok(txt):
        """Valida que la primera vi√±eta de üß≠ Respuesta ejecutiva tome postura clara."""
        m = re.search(r"üß≠\s*Respuesta\s+ejecutiva\s*(.+?)(?:\n\n[^\n]|$)", txt, flags=re.IGNORECASE | re.DOTALL)
        sec = m.group(1) if m else ""
        fb = re.search(r"^\s*[-‚Ä¢]\s*(.+)$", sec, flags=re.MULTILINE)
        if not fb:
            return False
        bullet = fb.group(1).strip().lower()
        keywords = ["s√≠", "si,", "no", "depende", "es legal", "no es legal", "permitido", "prohibido", "puedes", "no puedes"]
        return any(k in bullet for k in keywords)

    def _has_markdown_table(txt):
        """Chequea si hay una tabla Markdown b√°sica en el texto."""
        return bool(re.search(r"^\|.+\|\s*\n\|[-:\s|]+\|\s*\n(\|.*\|\s*\n)+", txt, flags=re.MULTILINE))

    # ---------- NUEVOS helpers para enlaces por secci√≥n ----------

    STOP_ES = {"de","la","las","los","un","una","uno","y","o","u","para","por","con","sin","del","al","en","que","como","cuando","donde","cu√°l","cu√°les","segun","ante","entre","hacia","hasta","sobre","tras","este","esta","esto"}

    def _domain_alias(url: str) -> str:
        """Devuelve alias corto para dominios gob.ec (SRI, IESS, MDT, SENADI‚Ä¶)."""
        try:
            d = urlparse(url).netloc.lower().replace("www.", "")
        except Exception:
            return "FUENTE"
        mapping = {
            "sri.gob.ec": "SRI",
            "iess.gob.ec": "IESS",
            "trabajo.gob.ec": "MDT",
            "ministeriodeltrabajo.gob.ec": "MDT",
            "derechosintelectuales.gob.ec": "SENADI",
            "snai.gob.ec": "SNAI",
            "uafe.gob.ec": "UAFE",
            "sercop.gob.ec": "SERCOP",
            "registrocivil.gob.ec": "REGISTRO CIVIL",
            "funcionjudicial.gob.ec": "FUNCI√ìN JUDICIAL",
            "corteconstitucional.gob.ec": "CORTE CONSTITUCIONAL",
            "ant.gob.ec": "ANT",
            "arcotel.gob.ec": "ARCOTEL",
            "arcsa.gob.ec": "ARCSA",
            "senescyt.gob.ec": "SENESCYT",
            "aduana.gob.ec": "SENAE",
        }
        if d in mapping:
            return mapping[d]
        # Si es .gob.ec: usa subdominio como alias (ej. "midena.gob.ec" -> "MIDENA")
        return (d.split(".")[0].upper() if d.endswith(".gob.ec") else d.upper())

    def _norm_terms(text: str) -> set:
        t = re.sub(r"[^a-z√°√©√≠√≥√∫√±√º0-9 ]+", " ", (text or "").lower())
        return {w for w in t.split() if len(w) > 2 and w not in STOP_ES}

    def _best_snippet_for(section_text: str, snips: list, min_overlap: int = 2):
        """Escoge el snippet web m√°s af√≠n a la secci√≥n por solapamiento de t√©rminos."""
        st = _norm_terms(section_text)
        best, score = None, 0
        for sn in snips or []:
            mix = " ".join([sn.get("title",""), sn.get("snippet","")])
            sc = len(st & _norm_terms(mix))
            if sc > score:
                best, score = sn, sc
        return best if score >= min_overlap else None

    def _split_by_sections(respuesta: str, sections: list):
        """Encuentra offsets de cada secci√≥n por el t√≠tulo exacto (l√≠nea completa)."""
        hits = []
        for s in sections:
            m = re.search(r"^" + re.escape(s) + r"\s*$", respuesta, flags=re.MULTILINE)
            if m: hits.append((s, m.start()))
        hits.sort(key=lambda x: x[1])
        chunks = []
        for i, (s, start) in enumerate(hits):
            end = hits[i+1][1] if i+1 < len(hits) else len(respuesta)
            chunks.append((s, start, end))
        return chunks

    def _attach_links_at_section_ends(respuesta: str, sections: list, snips: list) -> str:
        """A√±ade 'üîó <alias>' con enlace al final de cada secci√≥n (excepto Fuentes)."""
        chunks = _split_by_sections(respuesta, sections)
        if not chunks:
            return respuesta
        used = set()
        new_parts, last_end = [], 0
        for (title, start, end) in chunks:
            # Copia lo previo sin tocar
            new_parts.append(respuesta[last_end:start])
            segment = respuesta[start:end]
            if title.strip() != "üìö Fuentes consultadas":
                # Evitar reutilizar el mismo link en muchas secciones
                remaining = [r for r in (snips or []) if (r.get("link") or "") not in used]
                cand = _best_snippet_for(segment, remaining)
                if cand and cand.get("link"):
                    alias = _domain_alias(cand["link"])
                    link_html = f'\n\nüîó <a href="{html.escape(cand["link"])}" target="_blank" rel="noopener nofollow">{html.escape(alias)}</a>'
                    segment = segment.rstrip() + link_html + "\n"
                    used.add(cand["link"])
            new_parts.append(segment)
            last_end = end
        new_parts.append(respuesta[last_end:])
        return "".join(new_parts)

    def _mk_fuentes_html(snips, cap=7):
        """Lista HTML de fuentes (deduplicadas por dominio)."""
        if not snips:
            return "<p>‚Äî</p>"
        used_domains, items = set(), []
        for r in snips:
            u = (r.get("link") or "").strip()
            if not u:
                continue
            d = urlparse(u).netloc.replace("www.", "")
            if d in used_domains:
                continue
            t = html.escape(r.get("title") or d)
            items.append(f'<li><a href="{html.escape(u)}" target="_blank" rel="noopener nofollow">{t}</a> ‚Äî {html.escape(d)}</li>')
            used_domains.add(d)
            if len(items) >= cap:
                break
        return "<ul>" + "\n".join(items) + "</ul>"

    # ===================== Inicio del flujo =====================
    tokens_total = 0
    q = (question or "").strip()

    # ---------- A) SECTION PLANNER (elige 3‚Äì10 secciones) ----------
    planner_system = (
        "Eres un planificador de respuesta para un gerente en Ecuador. "
        "Elige ENTRE 3 Y 10 secciones con t√≠tulos claros (m√°x 35 caracteres cada uno) que mejor respondan la pregunta. "
        "SIEMPRE incluye como primera secci√≥n 'üß≠ Respuesta ejecutiva' y como √∫ltima 'üìö Fuentes consultadas'. "
        "Si el tema requiere plazos/responsables, incluye una secci√≥n con tabla. "
        "Devuelve SOLO JSON v√°lido con: {\"sections\": [\"t√≠tulo1\", ...]} "
        "(no agregues comentarios)."
    )
    planner_user = 'Pregunta: """' + q + '"""'

    kwargs_pl = dict(model=model, messages=[
        {"role": "system", "content": planner_system},
        {"role": "user", "content": planner_user}
    ])
    if is_gpt5:
        kwargs_pl["max_completion_tokens"] = 180
    else:
        kwargs_pl["temperature"] = max(0.2, temperature - 0.1)
        kwargs_pl["max_tokens"] = 180

    try:
        pl = openai_client.chat.completions.create(**kwargs_pl)
        plan_txt = (pl.choices[0].message.content or "").strip()
        tokens_total += pl.usage.total_tokens if getattr(pl, "usage", None) else 0
        try:
            plan = json.loads(plan_txt)
            sections = [s.strip() for s in (plan.get("sections") or []) if isinstance(s, str) and s.strip()]
        except Exception:
            sections = []
    except Exception:
        sections = []

    # Salvaguardas: garantizar cabeceras m√≠nimas
    if not sections:
        sections = ["üß≠ Respuesta ejecutiva", "üóìÔ∏è Plazos y responsables", "üí∏ Multas y riesgos", "‚úÖ Acciones inmediatas", "üßæ Checklist", "‚ùå Errores comunes", "üìö Fuentes consultadas"]
    # Normalizar y recortar 3‚Äì10
    if sections[0] != "üß≠ Respuesta ejecutiva":
        sections = ["üß≠ Respuesta ejecutiva"] + [s for s in sections if s != "üß≠ Respuesta ejecutiva"]
    if "üìö Fuentes consultadas" not in sections:
        sections.append("üìö Fuentes consultadas")
    if len(sections) < 3:
        sections = sections + ["‚úÖ Acciones inmediatas"]
    sections = sections[:10]
    if sections[-1] != "üìö Fuentes consultadas":
        sections = [s for s in sections if s != "üìö Fuentes consultadas"]
        sections.append("üìö Fuentes consultadas")

    # Detecta si hay una secci√≥n que implique tabla (por nombre)
    wants_table = any(any(k in s.lower() for k in ["plazo", "tabla", "responsable"]) for s in sections)

    # ---------- B) FUENTES: LEGAL_FACTS + WEB (gob.ec) ----------
    legal_facts_text = _compact_legal_text(context_docs)
    allowed_refs = _allowed_refs_from_docs(context_docs)  # (por si validas las citas inline)

    # WEB: Queries base (planner no retorna queries; usamos heur√≠stica + pregunta)
    queries = [
        q,
        q + " site:gob.ec",
        q + " site:trabajo.gob.ec",
        q + " site:iess.gob.ec",
        q + " site:sri.gob.ec",
        q + " site:derechosintelectuales.gob.ec",
    ]
    # Heur√≠stica tem√°tica simple
    ql = q.lower()
    if any(p in ql for p in ["contrato", "despido", "jornada", "sut", "ministerio", "trabajo"]):
        queries.append(q + " procedimiento site:trabajo.gob.ec")
    if any(p in ql for p in ["iess", "afili", "aporte"]):
        queries.append(q + " site:iess.gob.ec")
    if any(p in ql for p in ["iva", "retenci√≥n", "rdep", "ats", "sri", "formulario"]):
        queries.append(q + " site:sri.gob.ec")

    all_results = []
    for search_q in queries[:6]:
        all_results.extend(_google_cse(search_q, n=4))
    web_snippets = _mk_snippets(all_results, cap=8)
    web_context_text = _mk_web_text(web_snippets)

    # ---------- C) ANSWER WRITER ----------
    writer_system = (
        "Eres un abogado corporativo ecuatoriano para gerentes. "
        "Responde ‚Äòanswer-first‚Äô y llena TODAS las secciones listadas por el plan. "
        "Prioridad de informaci√≥n: 1) LEGAL_FACTS (tus art√≠culos). 2) WEB_SNIPPETS (gob.ec). 3) Conocimiento propio si no hay fuentes. "
        "Si aplicas una regla de LEGAL_FACTS, cierra la oraci√≥n con [C√ìDIGO Art. N]. "
        "Si falta un dato, usa ‚Äú‚Äî‚Äù en vez de inventar. "
        "No coloques enlaces en el cuerpo; las referencias web se a√±adir√°n autom√°ticamente al final de cada secci√≥n. "
        "En 'üìö Fuentes consultadas', lista 3‚Äì7 t√≠tulos + dominio (sin repetir dominios). "
        "Si no hay ninguna fuente web v√°lida, igualmente escribe la respuesta basada en conocimiento general y coloca '‚Äî' en Fuentes."
    )
    writer_user = (
        "PREGUNTA:\n" + q +
        "\n\nSECCIONES_PLAN (usa EXACTAMENTE estos encabezados, en orden):\n" + "\n".join(["- " + s for s in sections]) +
        "\n\nLEGAL_FACTS (usa como primera prioridad y cita inline [C√ìDIGO Art. N] cuando corresponda):\n" + legal_facts_text +
        "\n\nWEB_SNIPPETS (solo gob.ec; si est√° vac√≠o, puedes usar conocimiento del modelo):\n" + web_context_text +
        ("\n\nREQUISITO_TABLA: s√≠" if wants_table else "\n\nREQUISITO_TABLA: no") +
        "\n\nREGLAS DURAS:\n- No inventes montos/plazos.\n- Usa ‚Äú‚Äî‚Äù si un dato no aparece.\n- Tono profesional, directo, orientado a decisi√≥n.\n"
    )

    kwargs_w = dict(model=model, messages=[
        {"role": "system", "content": writer_system},
        {"role": "user", "content": writer_user}
    ])
    if is_gpt5:
        kwargs_w["max_completion_tokens"] = max_out
    else:
        kwargs_w["temperature"] = temperature
        kwargs_w["max_tokens"] = max_out

    wr = openai_client.chat.completions.create(**kwargs_w)
    respuesta = (wr.choices[0].message.content or "").strip()
    tokens_total += wr.usage.total_tokens if getattr(wr, "usage", None) else 0

    # ---------- D) QUALITY GATE ----------
    # 1) Todas las secciones del plan presentes (en orden flexible pero con todos los t√≠tulos exactos)
    missing = []
    for s in sections:
        if re.search(r"^" + re.escape(s) + r"\s*$", respuesta, flags=re.IGNORECASE | re.MULTILINE) is None:
            missing.append(s)

    # 2) Answer-first en la primera vi√±eta
    needs_answer_first = not _answer_first_ok(respuesta)

    # 3) Si se prometi√≥ tabla, verificar que exista al menos una tabla Markdown
    needs_table = wants_table and (not _has_markdown_table(respuesta))

    if missing or needs_answer_first or needs_table:
        problems = []
        if missing: problems.append("Faltan secciones: " + ", ".join(missing))
        if needs_answer_first: problems.append("La primera vi√±eta de ‚Äòüß≠ Respuesta ejecutiva‚Äô no toma postura clara.")
        if needs_table: problems.append("Se prometi√≥ tabla de plazos/responsables pero no se encontr√≥ una tabla.")

        fix_system = (
            "Corrige la respuesta para cumplir EXACTAMENTE con el plan de secciones y reglas. "
            "Mant√©n el contenido ya correcto; a√±ade o ajusta solo lo necesario. "
            "Si prometiste tabla de plazos/responsables, incluye una tabla Markdown. "
            "La primera vi√±eta de 'üß≠ Respuesta ejecutiva' debe tomar postura clara (‚ÄòS√≠, con condiciones‚Ä¶‚Äô, ‚ÄòNo, porque‚Ä¶‚Äô, ‚ÄòDepende: si‚Ä¶ entonces‚Ä¶‚Äô). "
            "No inventes datos: usa ‚Äú‚Äî‚Äù si falta."
        )
        fix_user = (
            "; ".join(problems) +
            "\n\nSECCIONES_PLAN:\n" + "\n".join(["- " + s for s in sections]) +
            ("\n\nREQUISITO_TABLA: s√≠" if wants_table else "\n\nREQUISITO_TABLA: no") +
            "\n\nRespuesta actual:\n" + respuesta
        )
        kwargs_fix = dict(model=model, messages=[
            {"role": "system", "content": fix_system},
            {"role": "user", "content": fix_user}
        ])
        if is_gpt5:
            kwargs_fix["max_completion_tokens"] = max_out
        else:
            kwargs_fix["temperature"] = max(0.2, temperature - 0.1)
            kwargs_fix["max_tokens"] = max_out

        wr2 = openai_client.chat.completions.create(**kwargs_fix)
        fixed = (wr2.choices[0].message.content or "").strip()
        if fixed:
            respuesta = fixed
            tokens_total += wr2.usage.total_tokens if getattr(wr2, "usage", None) else 0

    # ---------- E) Enlaces por secci√≥n + Fuentes HTML ----------
    # Inserta "üîó <ALIAS>" al final de cada secci√≥n (excepto la de fuentes)
    respuesta = _attach_links_at_section_ends(respuesta, sections, web_snippets)

    # Reemplaza el contenido de ‚Äúüìö Fuentes consultadas‚Äù con lista HTML
    fuentes_html = _mk_fuentes_html(web_snippets, cap=7)
    new_respuesta = re.sub(r"(üìö\s*Fuentes consultadas\s*)[\s\S]*$", r"\1\n" + fuentes_html, respuesta)
    if new_respuesta == respuesta:
        # Por si acaso no encontr√≥ la secci√≥n (no deber√≠a pasar), la agregamos al final
        respuesta = respuesta.rstrip() + "\n\nüìö Fuentes consultadas\n" + fuentes_html
    else:
        respuesta = new_respuesta

    # ---------- F) Notas operativas (opcional) ----------
    if contexto_practico:
        respuesta += "\n\nüß© Notas operativas (no normativo)\n" + (contexto_practico.strip()[:1200])

    # ---------- G) Fundamento legal (tus context_docs) ----------
    if context_docs:
        bloque = _mk_fundamento(context_docs)
        if bloque:
            # si el Writer hubiera agregado uno propio (no deber√≠a), lo removemos y ponemos el nuestro
            if "‚öñÔ∏è Fundamento legal" in respuesta:
                respuesta = re.split(r"\n?‚öñÔ∏è Fundamento legal.*", respuesta, maxsplit=1)[0].rstrip()
            respuesta += "\n\n" + bloque

    return respuesta, tokens_total


# ============= RESPUESTA EMPRESARIO API =============
def generate_legal_response_empresario_API(question, context_docs, contexto_practico=None):
    """
    Versi√≥n playground-like:
    - No usa context_docs ni a√±ade ‚öñÔ∏è Fundamento legal.
    - Delegado a Responses API + Web Search (GPT-5 mini).
    - Estructura pr√°ctica y enlaces como en Playground.
    """
    import re, html, logging
    from urllib.parse import urlparse

    # -------- Config (FORZAR GPT-5 mini) --------
    CONFIG = globals().get("CONFIG", {}) if "CONFIG" in globals() else {}
    model = CONFIG.get("OPENAI_MODEL_RESPONSES") or CONFIG.get("OPENAI_MODEL") or "gpt-5-mini"
    if not str(model).startswith("gpt-5"):
        model = "gpt-5-mini"
    max_out = int(CONFIG.get("MAX_TOKENS", 3000))
    temperature = 0.3
    logging.getLogger().warning(f"[Empresario_API|Playground] Using Responses model: {model}")

    # -------- Cliente (Responses API) --------
    try:
        from openai import OpenAI
        client = globals().get("openai_client", None)
        if client is None or not hasattr(client, "responses"):
            client = OpenAI()
    except Exception as e:
        return ("‚ö†Ô∏è Falta SDK OpenAI (instala `openai>=1.40`). Detalle: " + str(e), 0)

    # -------- Helpers --------
    def _mk_fuentes_html_from_urls(urls, titles=None, cap=7):
        titles = titles or {}
        used_domains, items = set(), []
        for u in urls:
            if not u:
                continue
            try:
                d = urlparse(u).netloc.replace("www.","")
            except Exception:
                d = ""
            if d in used_domains:
                continue
            t = html.escape(titles.get(u, d or "Fuente"))
            items.append(f'<li><a href="{html.escape(u)}" target="_blank" rel="noopener nofollow">{t}</a> ‚Äî {html.escape(d or "")}</li>')
            used_domains.add(d)
            if len(items) >= cap:
                break
        return "<ul>" + "\n".join(items) + "</ul>" if items else "<p>‚Äî</p>"

    def _extract_citations(resp):
        """Intenta recuperar URLs/t√≠tulos desde los eventos del Responses API; si no, regex del texto."""
        urls, titles = [], {}
        for item in (getattr(resp, "output", []) or []):
            try:
                meta = {}
                if isinstance(item, dict):
                    meta = (item.get("citation") or item.get("metadata") or item.get("source") or {})
                else:
                    meta = getattr(item, "citation", None) or getattr(item, "metadata", None) or {}
                url = (meta.get("url") or meta.get("href") or meta.get("source_url") or "").strip()
                ttl = (meta.get("title") or meta.get("source_title") or "").strip()
                if url and url not in urls:
                    urls.append(url)
                    if ttl:
                        titles[url] = ttl
            except Exception:
                pass
        text = (getattr(resp, "output_text", "") or "")
        if not urls and text:
            for m in re.findall(r"https?://[^\s\)\]\}<>\"']+", text):
                if m not in urls:
                    urls.append(m)
        return urls, titles

    # -------- Prompt estilo Playground (sin LEGAL_FACTS) --------
    q = (question or "").strip()

    SYSTEM = (
        "Eres un asesor experto en tr√°mites empresariales en Ecuador (es-EC, tz: America/Guayaquil). "
        "Usa la herramienta Web Search de forma ACTIVA (varias b√∫squedas y contraste) priorizando dominios oficiales "
        "(supercias.gob.ec, sri.gob.ec, gob.ec, funcionjudicial.gob.ec, registros mercantiles). "
        "Responde answer-first y NO inventes montos/plazos: si no est√°n claros, escribe ‚Äú‚Äî‚Äù y explica c√≥mo obtenerlos. "
        "FORMATO EXACTO (m√°x 8 secciones):\n"
        "1) üß≠ Respuesta ejecutiva (bullets cortos con veredicto claro: S√≠/No/Depende‚Ä¶)\n"
        "2) Pasos oficiales\n"
        "3) Documentos m√≠nimos\n"
        "4) Costos y tasas (si hay)\n"
        "5) Plazos t√≠picos (si hay)\n"
        "6) ‚úÖ Acciones inmediatas / ‚ùå Errores comunes (opcional)\n"
        "7) üß© Tips operativos (opcional)\n"
        "8) üìö Fuentes consultadas (obligatorio) como <ul> 5‚Äì7 enlaces (t√≠tulo + dominio), sin repetir dominio.\n"
        "Nunca dejes la respuesta sin texto final; si a√∫n est√°s buscando, escribe una s√≠ntesis √∫til igualmente."
    )

    USER = (
        "OBJETIVO: igualar el estilo del Playground con pasos oficiales, documentos m√≠nimos, costos/tasas y plazos, con enlaces oficiales.\n\n"
        "PREGUNTA:\n" + q
    )

    tools = [{"type": "web_search"}]
    tokens_total = 0

    # -------- Llamada principal (con web_search) --------
    try:
        r = client.responses.create(
            model=model,
            input=[{"role":"system","content":SYSTEM},
                   {"role":"user","content":USER}],
            tools=tools,
            max_output_tokens=max_out,
            temperature=temperature,
        )
    except Exception as e:
        # Fallback a web_search_preview si existe en el tenant
        try:
            r = client.responses.create(
                model=model,
                input=[{"role":"system","content":SYSTEM},
                       {"role":"user","content":USER}],
                tools=[{"type":"web_search_preview"}],
                max_output_tokens=max_out,
                temperature=temperature,
            )
        except Exception as e2:
            aviso = "‚ÑπÔ∏è Nota: tu cuenta no tiene habilitado Web Search en Responses API; el resultado puede diferir del Playground."
            return (aviso, 0)

    # -------- Salida del modelo --------
    respuesta = getattr(r, "output_text", "") or ""
    try:
        u = getattr(r, "usage", None)
        tokens_total = (getattr(u, "input_tokens", 0) or 0) + (getattr(u, "output_tokens", 0) or 0)
    except Exception:
        tokens_total = 0

    # -------- Si no devolvi√≥ texto, reintento sin herramientas (s√≠ntesis m√≠nima) --------
    if not respuesta.strip():
        r2 = client.responses.create(
            model=model,
            input=[
                {"role":"system","content":"Responde en el formato pedido, AUN SIN BUSCAR, usando ‚Äú‚Äî‚Äù donde falten datos, y SIEMPRE incluye 'üìö Fuentes consultadas' con una lista vac√≠a si no tienes enlaces."},
                {"role":"user","content":USER}
            ],
            max_output_tokens=min(max_out, 800),
            temperature=0.2,
        )
        respuesta = getattr(r2, "output_text", "") or ""
        try:
            u2 = getattr(r2, "usage", None)
            tokens_total += (getattr(u2, "input_tokens", 0) or 0) + (getattr(u2, "output_tokens", 0) or 0)
        except Exception:
            pass

    # -------- Forzar secci√≥n de Fuentes si falta --------
    if "üìö Fuentes consultadas" not in respuesta:
        urls, titles = _extract_citations(r)
        fuentes_html = _mk_fuentes_html_from_urls(urls, titles, cap=7)
        respuesta = respuesta.rstrip() + "\n\nüìö Fuentes consultadas\n" + fuentes_html
    else:
        # Si existe la secci√≥n pero sin <ul>, la completamos con las citas detectadas
        if "<ul>" not in respuesta:
            urls, titles = _extract_citations(r)
            fuentes_html = _mk_fuentes_html_from_urls(urls, titles, cap=7)
            # Reemplaza el bloque de fuentes por nuestra lista HTML
            respuesta = re.sub(r"(üìö\s*Fuentes consultadas\s*)[\s\S]*$", r"\1\n" + fuentes_html, respuesta)

    return respuesta, tokens_total





# ============= RESPUESTA PR√ÅCTICA =============

def obtener_respuesta_practica(question, score=None):
    practical_index_name = "indice-respuestas-abogados"
    practical_index = pc.Index(practical_index_name)

    practical_vector_store = PineconeVectorStore(
        pinecone_index=practical_index
    )

    practical_index_instance = VectorStoreIndex.from_vector_store(
        vector_store=practical_vector_store,
        service_context=service_context
    )

    engine = practical_index_instance.as_query_engine(similarity_top_k=1)
    resultado = engine.query(question)

    if not resultado.source_nodes:
        return None

    texto_practico = resultado.response.strip()

    # Elegir introducci√≥n seg√∫n el score
    if score is not None and score < 0.75:
        introduccion = (
            "‚ùó La respuesta no responde directamente a la pregunta del usuario.\n"
            "- Introduce con una frase como:\n"
            "  \"Es dif√≠cil indicarte si [reformula aqu√≠ la intenci√≥n del usuario], en este caso es importante que un abogado experto te asesore. Sin embargo, puedo decirte que...\"\n"
            "- Reformula despu√©s el contenido original como referencia general.\n"
            "- No afirmes nada que no est√© expresamente en el texto original.\n"
        )
    else:
        introduccion = (
            "‚úÖ La respuesta es clara y √∫til para la pregunta del usuario:\n"
            "- Reform√∫lala sin alterar el mensaje, con un tono claro, amable y profesional.\n"
        )

    # Prompt final
    prompt = (
        "Reformula esta respuesta pr√°ctica legal para que suene humana, emp√°tica, cercana y √∫til para alguien sin conocimientos jur√≠dicos. Usa segunda persona. Eval√∫a si responde o no directamente a la siguiente pregunta:\n\n"
        f"üßë‚Äç‚öñÔ∏è Pregunta del usuario: \"{question}\"\n\n"
        f"{introduccion}\n"
        "üîí Reglas adicionales:\n"
        "- Conserva enlaces web √∫tiles como http://consultas.funcionjudicial.gob.ec si est√°n presentes en el texto original.\n"
        "- NO agregues enlaces si no est√°n.\n"
        "- Elimina nombres propios, montos espec√≠ficos, fechas y datos sensibles.\n\n"
        f"Texto original:\n{texto_practico}"
    )

    # Llamada a OpenAI
    reformulado = openai_client.chat.completions.create(
        model=CONFIG["OPENAI_MODEL"],
        messages=[
            {"role": "system", "content": "Eres un asistente legal emp√°tico que habla en tono claro y humano."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.4,
        max_tokens=800
    )

    return reformulado.choices[0].message.content.strip()


# ============= ENDPOINT PRINCIPAL =============
@app.route("/query", methods=["GET", "POST"])
def handle_query():
    try:
        question = request.args.get("question", "").strip() if request.method == "GET" else request.get_json().get("question", "").strip()
        if not question:
            return jsonify({"error": "Se requiere 'question'"}), 400

        # ========== CONTEXTO LEGAL ==========
        query_engine = index.as_query_engine(similarity_top_k=TOP_K_RESULTS)
        pinecone_response = query_engine.query(question)

        context_docs = []
        biografia_juridica = {"alta": [], "media": [], "baja": []}

        total_docs = len(pinecone_response.source_nodes)
        alta_limite = int(total_docs * 0.3)
        media_limite = int(total_docs * 0.6)

        for i, node in enumerate(pinecone_response.source_nodes):
            metadata = getattr(node.node, 'metadata', {})
            codigo = metadata.get('code', '')
            articulo = metadata.get('article', '')
            texto = getattr(node.node, 'text', '') or metadata.get("text", '')
            texto = texto.strip()

            doc_data = {"codigo": codigo, "articulo": articulo, "texto": texto}
            context_docs.append(doc_data)

            if i < alta_limite:
                biografia_juridica["alta"].append(doc_data)
            elif i < media_limite:
                biografia_juridica["media"].append(doc_data)
            else:
                biografia_juridica["baja"].append(doc_data)

        if not context_docs:
            return jsonify({"respuesta": "No encontr√© normativa aplicable. No me baso en ning√∫n art√≠culo."})

        # ========== RESPUESTAS ==========
        respuesta_legal, tokens_usados = generate_legal_response5(question, context_docs)

        index_respuestas_abogados = pc.Index("indice-respuestas-abogados")
        embedding = embed_model._get_query_embedding(question)
        similares = index_respuestas_abogados.query(vector=embedding, top_k=1, include_metadata=True)

        respuesta_practica_reformulada = None

        if similares.get("matches"):
            match = similares["matches"][0]
            score = match.get("score", 0)
            if score >= 0.6:
                respuesta_practica_reformulada = obtener_respuesta_practica(question, score=score)
            else:
                respuesta_practica_reformulada = None

        # ========== UNIFICAR RESPUESTA ==========
        bloques = []

        if respuesta_practica_reformulada:
            bloques.append("üìå Recomendaci√≥n pr√°ctica:\n" + respuesta_practica_reformulada.strip())

        bloques.append("‚öñÔ∏è Fundamento legal:\n" + respuesta_legal.strip())

        return jsonify({
            "respuesta": "\n\n---\n\n".join(bloques),
            "biografia_juridica": biografia_juridica,
            "tokens_usados": {"total_tokens": tokens_usados}
        })

    except Exception as e:
        return jsonify({"error": str(e), "traceback": traceback.format_exc()}), 500



# ============= ENDPOINT PRINCIPAL =============
@app.route("/queryEmpresario", methods=["GET", "POST"])
def handle_query_empresario():
    try:
        question = request.args.get("question", "").strip() if request.method == "GET" else request.get_json().get("question", "").strip()
        if not question:
            return jsonify({"error": "Se requiere 'question'"}), 400

        # ========== CONTEXTO LEGAL ==========
        query_engine = index.as_query_engine(similarity_top_k=TOP_K_RESULTS)
        pinecone_response = query_engine.query(question)

        context_docs = []
        biografia_juridica = {"alta": [], "media": [], "baja": []}

        total_docs = len(pinecone_response.source_nodes)
        alta_limite = int(total_docs * 0.3)
        media_limite = int(total_docs * 0.6)

        for i, node in enumerate(pinecone_response.source_nodes):
            metadata = getattr(node.node, 'metadata', {})
            codigo = metadata.get('code', '')
            articulo = metadata.get('article', '')
            texto = getattr(node.node, 'text', '') or metadata.get("text", '')
            texto = texto.strip()

            doc_data = {"codigo": codigo, "articulo": articulo, "texto": texto}
            context_docs.append(doc_data)

            if i < alta_limite:
                biografia_juridica["alta"].append(doc_data)
            elif i < media_limite:
                biografia_juridica["media"].append(doc_data)
            else:
                biografia_juridica["baja"].append(doc_data)

      
        # ========== RESPUESTAS ==========
        respuesta_legal, tokens_usados = generate_legal_response_empresario_API(question, context_docs)

        index_respuestas_abogados = pc.Index("indice-respuestas-abogados")
        embedding = embed_model._get_query_embedding(question)
        similares = index_respuestas_abogados.query(vector=embedding, top_k=1, include_metadata=True)

        respuesta_practica_reformulada = None

        if similares.get("matches"):
            match = similares["matches"][0]
            score = match.get("score", 0)
            if score >= 0.6:
                respuesta_practica_reformulada = obtener_respuesta_practica(question, score=score)
            else:
                respuesta_practica_reformulada = None

        # ========== UNIFICAR RESPUESTA ==========
        bloques = []

        if respuesta_practica_reformulada:
            bloques.append("üìå Recomendaci√≥n pr√°ctica:\n" + respuesta_practica_reformulada.strip())

        bloques.append("‚öñÔ∏è Fundamento legal:\n" + respuesta_legal.strip())

        return jsonify({
            "respuesta": "\n\n---\n\n".join(bloques),
            "biografia_juridica": biografia_juridica,
            "tokens_usados": {"total_tokens": tokens_usados}
        })

    except Exception as e:
        return jsonify({"error": str(e), "traceback": traceback.format_exc()}), 500

import tiktoken

from flask import send_from_directory
from docx import Document
import uuid
import os

# Endpoint de descarga (a√±√°delo solo una vez en tu app)
@app.route("/descargar/<filename>")
def descargar_archivo(filename):
    return send_from_directory("archivos_temp", filename, as_attachment=True)

# Funci√≥n auxiliar para guardar y generar link
def guardar_docx_y_retornar_link(texto, host_url):
    filename = f"{uuid.uuid4()}.docx"
    filepath = os.path.join("archivos_temp", filename)
    os.makedirs("archivos_temp", exist_ok=True)

    doc = Document()
    for linea in texto.split('\n'):
        doc.add_paragraph(linea)
    doc.save(filepath)

    return f"{host_url}descargar/{filename}"

# ======================= GENERAR CONTRATO COMPLETO =======================
@app.route("/generar-contrato-completo", methods=["POST"])
def generar_contrato_completo():
    try:
        data = request.get_json()
        pregunta = data.get("pregunta", "").strip()

        if not pregunta:
            return jsonify({"error": "La pregunta es obligatoria"}), 400

        contrato_query_engine = contratos_index.as_query_engine(similarity_top_k=1)
        resultado_contrato = contrato_query_engine.query(pregunta)

        contrato_base = ""
        if resultado_contrato.source_nodes:
            contrato_base = resultado_contrato.source_nodes[0].node.text.strip()

        if contrato_base:
            prompt = f"""
Eres un abogado ecuatoriano experto en redacci√≥n de documentos legales. A continuaci√≥n tienes un modelo jur√≠dico que debes adaptar para responder a la solicitud del usuario. Mant√©n su estructura y estilo, pero personaliza el contenido seg√∫n la petici√≥n.

üìÑ Solicitud del usuario:
{pregunta}

üìë Modelo de referencia:
{contrato_base}

‚úçÔ∏è Instrucciones:
- No incluyas explicaciones, solo el documento.
- Usa lenguaje jur√≠dico claro.
- Usa campos gen√©ricos como [NOMBRE], [FECHA], etc.
""".strip()

            def contar_tokens(texto):
                enc = tiktoken.encoding_for_model("gpt-3.5-turbo")
                return len(enc.encode(texto))

            tokens_prompt = contar_tokens(prompt)

            if tokens_prompt <= 3000:
                modelo = "gpt-3.5-turbo"
                max_tokens_salida = 1000
            else:
                modelo = "gpt-4o"
                max_tokens_salida = 8000

            response = openai_client.chat.completions.create(
                model=modelo,
                messages=[
                    {"role": "system", "content": "Eres un abogado ecuatoriano experto en redacci√≥n legal."},
                    {"role": "user", "content": prompt}
                ],
                temperature=CONFIG["TEMPERATURE"],
                max_tokens=max_tokens_salida
            )

            texto = response.choices[0].message.content.strip()
            tokens = response.usage.total_tokens

            if tokens > 8000:
                url = guardar_docx_y_retornar_link(texto, request.host_url)
                return jsonify({
                    "respuesta": f"‚úÖ El documento ha sido generado correctamente. <a href='{url}' target='_blank'>Haz clic aqu√≠ para descargarlo en Word (.docx)</a>.",
                    "tokens_usados": { "total_tokens": tokens },
                    "biografia_juridica": None
                })

            return jsonify({
                "respuesta": texto,
                "tokens_usados": { "total_tokens": tokens },
                "biografia_juridica": None
            })

        query_engine = index.as_query_engine(similarity_top_k=10)
        resultado = query_engine.query(pregunta)

        contexto_legal = []
        biografia_juridica = {"alta": [], "media": [], "baja": []}

        total_docs = len(resultado.source_nodes)
        alta_limite = int(total_docs * 0.3)
        media_limite = int(total_docs * 0.6)

        for i, nodo in enumerate(resultado.source_nodes):
            meta = getattr(nodo.node, 'metadata', {})
            codigo = meta.get("code", "")
            articulo = meta.get("article", "")
            texto = getattr(nodo.node, 'text', '') or meta.get("text", '')
            texto = texto.strip()

            if codigo and articulo:
                contexto_legal.append(f"{codigo} Art. {articulo}: {texto[:500]}")
                doc = {"codigo": codigo, "articulo": articulo, "texto": texto}

                if i < alta_limite:
                    biografia_juridica["alta"].append(doc)
                elif i < media_limite:
                    biografia_juridica["media"].append(doc)
                else:
                    biografia_juridica["baja"].append(doc)

        prompt = f"""
Eres un abogado ecuatoriano experto en redacci√≥n de documentos legales. Vas a redactar un texto profesional, completo y jur√≠dicamente v√°lido, en respuesta a la solicitud del usuario.

‚úçÔ∏è Instrucciones estrictas:
- Redacta directamente el documento legal solicitado, sin explicaciones ni introducciones.
- Usa lenguaje legal claro y preciso, adecuado al sistema jur√≠dico del Ecuador.
- Si el documento requiere estructura (contrato, demanda, reglamento, etc.), incluye numeraci√≥n adecuada: cl√°usulas, art√≠culos, incisos.
- Si el documento es breve (como una solicitud o escrito procesal), redacta en formato carta legal.
- Utiliza campos gen√©ricos para datos personales: [NOMBRE], [FECHA], [CANTIDAD], [CIUDAD], etc.
- No agregues art√≠culos legales inventados: usa solo los del contexto.

üìÑ Solicitud del usuario:
{pregunta}

üìö Contexto legal (solo puedes usar esto):
{chr(10).join(contexto_legal)}

üßæ Al final del documento, incluye una secci√≥n con el encabezado ‚ÄúFundamento legal‚Äù y menciona los art√≠culos usados.
""".strip()

        response = openai_client.chat.completions.create(
            model=CONFIG["OPENAI_MODEL"],
            messages=[
                {"role": "system", "content": "Eres un abogado ecuatoriano experto en redacci√≥n legal."},
                {"role": "user", "content": prompt}
            ],
            temperature=CONFIG["TEMPERATURE"],
            max_tokens=CONFIG["MAX_TOKENS"] - 500
        )

        texto = response.choices[0].message.content.strip()
        tokens = response.usage.total_tokens

        if tokens > 8000:
            url = guardar_docx_y_retornar_link(texto, request.host_url)
            return jsonify({
                "respuesta": f"‚úÖ El documento ha sido generado correctamente. <a href='{url}' target='_blank'>Haz clic aqu√≠ para descargarlo en Word (.docx)</a>.",
                "tokens_usados": { "total_tokens": tokens },
                "biografia_juridica": biografia_juridica
            })

        return jsonify({
            "respuesta": texto,
            "tokens_usados": { "total_tokens": tokens },
            "biografia_juridica": biografia_juridica
        })

    except Exception as e:
        return jsonify({"error": str(e), "traceback": traceback.format_exc()}), 500

# ============= WEBSEARCH PRINCIPAL =============

@app.route("/envtest", methods=["GET"])
def env_test():
    return jsonify({
        "GOOGLE_API_KEY": os.getenv("GOOGLE_API_KEY"),
        "SEARCH_ENGINE_ID": os.getenv("SEARCH_ENGINE_ID")
    })


GOOGLE_API_KEY = os.getenv("GOOGLE_SEARCH_API_KEY")
SEARCH_ENGINE_ID = os.getenv("GOOGLE_CX")


from llama_index.schema import Document  # ‚úÖ Importaci√≥n correcta para tu versi√≥n

import os
import requests
from bs4 import BeautifulSoup
from flask import request, jsonify
from llama_index import VectorStoreIndex, Document
import traceback

SCRAPER_API_KEY = os.getenv("SCRAPER_API_KEY")  # Aseg√∫rate de definirlo en tu entorno

@app.route("/websearch", methods=["POST"])
def websearch():
    try:
        pregunta = request.get_json().get("pregunta", "").strip()
        if not pregunta:
            return jsonify({"error": "Se requiere 'pregunta'"}), 400

        # ===== Buscar en √≠ndice de respuestas pr√°cticas =====
        index_respuestas_abogados = pc.Index("indice-respuestas-abogados")
        embedding = embed_model._get_query_embedding(pregunta)

        similares = index_respuestas_abogados.query(
            vector=embedding,
            top_k=1,
            include_metadata=True
        )

        mostrar_respuesta_practica = False
        mostrar_google = True
        respuesta_practica_html = ""

        score = 0
        if similares.get("matches"):
            match = similares["matches"][0]
            score = match.get("score", 0)

            if score >= 0.70:
                mostrar_respuesta_practica = True
                mostrar_google = False
            elif 0.60 <= score < 0.70:
                mostrar_respuesta_practica = True
                mostrar_google = True
            else:
                mostrar_google = True

            if mostrar_respuesta_practica:
                respuesta_practica = obtener_respuesta_practica(pregunta, score=score)
                if respuesta_practica:
                    respuesta_practica_html = f"<h3>üìå Recomendaci√≥n pr√°ctica</h3><div class='chat-respuesta'>{respuesta_practica}</div>"
                    if mostrar_google:
                        respuesta_practica_html += "<hr>"

        respuesta_google_html = ""
        tokens = 0

        if mostrar_google:
            # ===== Buscar en Google =====
            search_url = "https://www.googleapis.com/customsearch/v1"
            search_params = {
                "key": GOOGLE_API_KEY,
                "cx": SEARCH_ENGINE_ID,
                "q": pregunta,
                "siteSearch": "gob.ec",
                "siteSearchFilter": "i"
            }
            search_resp = requests.get(search_url, params=search_params)
            search_resp.raise_for_status()
            resultados = search_resp.json().get("items", [])[:5]

            if not resultados:
                respuesta_google_html = "<h3>üåê Respuesta basada en Google</h3><div class='chat-respuesta'>‚ùå No se encontraron p√°ginas relevantes.</div>"
            else:
                contexto = "\n".join(
                    [f"T√≠tulo: {item['title']}\nLink: {item['link']}" for item in resultados]
                )

                prompt = f"""
Eres un abogado experto. Un usuario te hace la siguiente pregunta:

\"{pregunta}\"

Google te ha mostrado los siguientes resultados relacionados:

{contexto}

Tu tarea es:

1. Responder al usuario de manera clara y directa, en un p√°rrafo.
2. Indicar que debe realizar el proceso en fuentes oficiales.
3. Recomendar los enlaces m√°s √∫tiles (basado en los t√≠tulos) ordenados por relevancia para que el usuario contin√∫e su tr√°mite.

Responde con lenguaje humano, sin tecnicismos innecesarios y sin inventar datos que no est√©n respaldados por los t√≠tulos mostrados.
""".strip()

                response = openai_client.chat.completions.create(
                    model=CONFIG["OPENAI_MODEL"],
                    messages=[
                        {"role": "system", "content": "Eres un abogado experto que ayuda con tr√°mites legales en Ecuador."},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=CONFIG["TEMPERATURE"],
                    max_tokens=800
                )

                respuesta_ia_cruda = response.choices[0].message.content.strip()
                tokens = response.usage.total_tokens

                enlaces_html = []
                for i, item in enumerate(resultados, 1):
                    titulo = item.get("title", f"Fuente {i}").strip()
                    url = item.get("link", "#")
                    enlaces_html.append(f"<li>üîó <strong>{titulo}</strong><br><a href='{url}' target='_blank'>{url}</a></li>")

                if enlaces_html:
                    respuesta_ia_cruda += "<br><br><ul class='fuentes-web'>" + "\n".join(enlaces_html) + "</ul>"

                respuesta_google_html = f"<h3>üåê Respuesta basada en Google</h3><div class='chat-respuesta'>{respuesta_ia_cruda}</div>"

        # ========== RESPUESTA FINAL ==========
        return jsonify({
            "respuesta": respuesta_practica_html + respuesta_google_html,
            "tokens_usados": {"total_tokens": tokens},
            "biografia_juridica": ""
        })

    except Exception as e:
        return jsonify({"error": str(e), "traceback": traceback.format_exc()}), 500


# ============= ENDPOINT PRINCIPAL =============
@app.route("/test-contexto-practico", methods=["POST"])
def test_contexto_practico():
    try:
        data = request.get_json()
        question = data.get("question", "").strip() if data else ""
        if not question:
            return jsonify({"error": "Se requiere 'question'"}), 400

        index_respuestas_abogados = pc.Index("indice-respuestas-abogados")
        embedding = embed_model._get_query_embedding(question)

        similares = index_respuestas_abogados.query(
            vector=embedding,
            top_k=1,
            include_metadata=True
        )

        if not similares.get("matches"):
            return jsonify({"respuesta": "‚ùå No se encontr√≥ coincidencia."})

        match = similares["matches"][0]
        score = match["score"]
        idea = match["metadata"].get("respuesta_abogado", "")
        descripcion = match["metadata"].get("descripcion", "")

        contexto_practico = f'En casos como "{descripcion.lower()}" se suele actuar de la siguiente forma: {idea[:300]}...'

        return jsonify({
            "score": score,
            "descripcion": descripcion,
            "respuesta_abogado": idea,
            "contexto_practico": contexto_practico
        })

    except Exception as e:
        return jsonify({"error": str(e), "traceback": traceback.format_exc()}), 500


# ============= probar 5 =============
import time


import time

@app.route("/gpt5/test2", methods=["GET"])
def gpt5_test():
    try:
        prompt = request.args.get("q", "Di 'pong' y el nombre exacto del modelo que est√°s usando.")
        t0 = time.time()
        resp = openai_client.chat.completions.create(
            model="gpt-5-mini",
            messages=[
                {"role": "system", "content": "Eres un probador m√≠nimo. Responde en una sola l√≠nea."},
                {"role": "user", "content": prompt}
            ],
            # GPT-5: NO usar temperature; usa el default del modelo
            max_completion_tokens=50  # reemplaza max_tokens por max_completion_tokens
        )
        latency_ms = int((time.time() - t0) * 1000)
        content = resp.choices[0].message.content.strip()
        model_used = getattr(resp, "model", "gpt-5-mini")
        tokens = resp.usage.total_tokens if getattr(resp, "usage", None) else None

        return jsonify({"ok": True, "model": model_used, "latency_ms": latency_ms,
                        "total_tokens": tokens, "sample": content})
    except Exception as e:
        return jsonify({"ok": False, "error": str(e), "traceback": traceback.format_exc()}), 500

@app.route("/responses/toolcheck", methods=["GET"])
def responses_toolcheck():
    """
    Verifica si Web Search est√° habilitado para Responses API con gpt-5-mini.
    - Paso 1 (ping): intenta una llamada con tools=[{"type": "web_search"}] para confirmar que el endpoint acepta la herramienta.
    - Paso 2 (uso): instruye a hacer UNA b√∫squeda y luego responder 'ok'; intenta detectar si hubo se√±ales de uso de la herramienta.
    """
    from openai import OpenAI
    from flask import jsonify

    try:
        # Cliente OpenAI (usa el global si existe)
        client = globals().get("openai_client") or OpenAI(api_key=CONFIG.get("OPENAI_API_KEY"))

        model = "gpt-5-mini"  # Fijamos el modelo a probar

        # ----- Paso 1: ping (¬øel endpoint acepta la herramienta?) -----
        try:
            ping = client.responses.create(
                model=model,
                input=[{"role": "user", "content": "di 'ok'"}],
                tools=[{"type": "web_search"}],
                max_output_tokens=32,  # >= 16 para evitar error de m√≠nimo
            )
            ping_model = getattr(ping, "model", model)
        except Exception as e_ping:
            return jsonify({
                "ok": False,
                "model_requested": model,
                "web_search_enabled": False,  # No acept√≥ la herramienta
                "error": str(e_ping),
            }), 200

        # ----- Paso 2: intento de uso (sin tool_choice; solo instrucci√≥n) -----
        try:
            r = client.responses.create(
                model=model,
                input=[
                    {"role": "system", "content": "Haz exactamente UNA b√∫squeda web y luego responde solo con 'ok'."},
                    {"role": "user", "content": "Encuentra la p√°gina oficial del Servicio de Rentas Internas de Ecuador (SRI) usando la herramienta y luego responde 'ok'."}
                ],
                tools=[{"type": "web_search"}],
                max_output_tokens=64
            )

            # Extraer se√±ales de uso (heur√≠stica sobre metadatos en la salida estructurada)
            used = False
            try:
                for item in (getattr(r, "output", []) or []):
                    meta = None
                    if isinstance(item, dict):
                        meta = item.get("citation") or item.get("metadata") or item.get("source")
                    else:
                        meta = getattr(item, "citation", None) or getattr(item, "metadata", None)
                    if meta:
                        u = (meta.get("url") or meta.get("href") or meta.get("source_url") or "")
                        if u:
                            used = True
                            break
            except Exception:
                used = False

            usage = getattr(r, "usage", None)
            return jsonify({
                "ok": True,
                "model_used": getattr(r, "model", ping_model),
                "web_search_enabled": True,               # El ping pas√≥: la herramienta est√° habilitada
                "web_search_used_in_call": used,          # Se√±al (heur√≠stica) de uso real en esta llamada
                "output": getattr(r, "output_text", ""),
                "input_tokens": getattr(usage, "input_tokens", None) if usage else None,
                "output_tokens": getattr(usage, "output_tokens", None) if usage else None,
            }), 200

        except Exception as e_use:
            # La herramienta est√° habilitada (pas√≥ el ping), pero esta llamada fall√≥ por otro motivo
            return jsonify({
                "ok": True,
                "model_used": ping_model,
                "web_search_enabled": True,
                "web_search_used_in_call": False,
                "error_in_use_call": str(e_use),
            }), 200

    except Exception as e:
        return jsonify({"ok": False, "error": str(e)}), 500





if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5001, debug=True)
